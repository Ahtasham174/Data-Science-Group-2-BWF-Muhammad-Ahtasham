{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f0c4d0-9fde-4f34-961f-07bc196943e3",
   "metadata": {},
   "source": [
    "# Task 15: Data Wrangling: Join, Combine, and Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9534d6-fb28-45ae-8c71-6f965ec40cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b668415-69bd-4452-be98-8a33be27e464",
   "metadata": {},
   "source": [
    "## 1. Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d6e5e-6387-4b85-9f2b-deacc3a92bdc",
   "metadata": {},
   "source": [
    "### Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dd1294-dc4f-4d5a-9c82-e05dfdd641d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge on ID using inner join:\n",
      "    ID   Name  Age\n",
      "0   1    Ali   25\n",
      "1   2  Ahmed   30\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Ali', 'Ahmed', 'Asad']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2, 4], 'Age': [25, 30, 35]})\n",
    "i_j = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(\"Merge on ID using inner join:\\n\", i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82537c1-1c6f-4d43-bc91-73b49306f5b6",
   "metadata": {},
   "source": [
    "### Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4527bc3-7f68-4d9d-b8a7-f774447bab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge on ID using outer join:\n",
      "    ID   Name   Age\n",
      "0   1    Ali  25.0\n",
      "1   2  Ahmed  30.0\n",
      "2   3   Asad   NaN\n",
      "3   4    NaN  35.0\n"
     ]
    }
   ],
   "source": [
    "o_j = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(\"Merge on ID using outer join:\\n\", o_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c4da8-fd19-44f8-91ac-8ff16b81de0d",
   "metadata": {},
   "source": [
    "### Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2adda919-3241-4bf7-9c85-482a835f0c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge on ID using left join:\n",
      "    ID   Name   Age\n",
      "0   1    Ali  25.0\n",
      "1   2  Ahmed  30.0\n",
      "2   3   Asad   NaN\n"
     ]
    }
   ],
   "source": [
    "l_j = pd.merge(df1, df2, on='ID', how='left')\n",
    "print(\"Merge on ID using left join:\\n\", l_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377a5dd-a251-4071-942a-a59fc0a6caad",
   "metadata": {},
   "source": [
    "### Right Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873c1577-90b2-4c54-b4de-a49830a0e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge on ID using right join:\n",
      "    ID   Name  Age\n",
      "0   1    Ali   25\n",
      "1   2  Ahmed   30\n",
      "2   4    NaN   35\n"
     ]
    }
   ],
   "source": [
    "r_j = pd.merge(df1, df2, on='ID', how='right')\n",
    "print(\"Merge on ID using right join:\\n\", r_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124edea-fe5d-40bf-8c7b-24fe4c9c0340",
   "metadata": {},
   "source": [
    "## 2. Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e6c4d-436b-4506-8176-130a413b3560",
   "metadata": {},
   "source": [
    "### Concatenation along Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02be26aa-5d98-400b-bc10-809fd3ef8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatinating along rows:\n",
      "    ID          Name\n",
      "0   1           Ali\n",
      "1   2         Ahmed\n",
      "2   3          Asad\n",
      "0   4  Abdul Rehman\n",
      "1   5         Awais\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'ID': [4, 5], 'Name': ['Abdul Rehman', 'Awais']})\n",
    "conc = pd.concat([df1, df3], axis=0)\n",
    "print(\"Concatinating along rows:\\n\", conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671a745-f358-491a-9a57-b235945cc2eb",
   "metadata": {},
   "source": [
    "### Concatenation along Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f26da00-efa8-4990-a9ec-931375010c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatinating along columns:\n",
      "    ID   Name City\n",
      "0   1    Ali  RWP\n",
      "1   2  Ahmed  ISL\n",
      "2   3   Asad  LHR\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.DataFrame({'City': ['RWP', 'ISL', 'LHR']})\n",
    "concat = pd.concat([df1, df4], axis=1)\n",
    "print(\"Concatinating along columns:\\n\", concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c223cc-9897-487e-90cb-0df28e1ef5ae",
   "metadata": {},
   "source": [
    "### Concatenate a List of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac5cde4-bf1b-416f-a700-b9631b96652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated List:\n",
      "    ID   Name  ID  Age City\n",
      "0   1    Ali   1   25  RWP\n",
      "1   2  Ahmed   2   30  ISL\n",
      "2   3   Asad   4   35  LHR\n"
     ]
    }
   ],
   "source": [
    "dfs = [df1, df2, df4]\n",
    "concat_list = pd.concat(dfs, axis=1)\n",
    "print(\"Concatenated List:\\n\", concat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8386e-6c4a-444b-83fd-b5c28fc1a0e8",
   "metadata": {},
   "source": [
    "## 3. Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d4934-279c-4cbd-92e7-207e03f3412f",
   "metadata": {},
   "source": [
    "### Merging on a Single Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a458952f-e486-4b41-b594-4cf850c4bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Merge:\n",
      "    ID   Name  Age\n",
      "0   1    Ali   25\n",
      "1   2  Ahmed   30\n"
     ]
    }
   ],
   "source": [
    "single = pd.merge(df1, df2, on='ID')\n",
    "print(\"Single Merge:\\n\", single)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fddcfb-2373-4a96-a3ee-a09430dae8e0",
   "metadata": {},
   "source": [
    "### Merging on Multiple Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88afd85-5cd1-46d7-a91f-a07669d28a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Merge:\n",
      "    ID Dept       Course Grade\n",
      "0   1   ME     Calculas    B+\n",
      "1   2  PHY  Electronics    A+\n",
      "2   3   CS          CFP    A-\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.DataFrame({'ID': [1, 2, 3], 'Dept': ['ME', 'PHY', 'CS'], 'Course': ['Calculas', 'Electronics', 'CFP']})\n",
    "df6 = pd.DataFrame({'ID': [1, 2, 3], 'Dept': ['ME', 'PHY', 'CS'], 'Grade': ['B+', 'A+', 'A-']})\n",
    "multiple = pd.merge(df5, df6, on=['ID', 'Dept'])\n",
    "print(\"Multiple Merge:\\n\", multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f3941-0164-4609-ac09-e33bea8c39e9",
   "metadata": {},
   "source": [
    "## 4. Reshaping DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7883c-b82c-4936-b1db-ccd56a925694",
   "metadata": {},
   "source": [
    "### Melting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fe3c1b9-760f-43e9-a8cf-0f6d56883bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melted reshaping:\n",
      "    ID  Subject  Score\n",
      "0   1     Math     85\n",
      "1   2     Math     90\n",
      "2   3     Math     95\n",
      "3   1  Science     80\n",
      "4   2  Science     85\n",
      "5   3  Science     90\n"
     ]
    }
   ],
   "source": [
    "df7 = pd.DataFrame({ 'ID': [1, 2, 3], 'Math': [85, 90, 95], 'Science': [80, 85, 90] })\n",
    "melted = pd.melt(df7, id_vars=['ID'], value_vars=['Math', 'Science'], var_name='Subject', value_name='Score')\n",
    "print(\"Melted reshaping:\\n\", melted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef1b50-ef6a-4445-9182-159453644e0a",
   "metadata": {},
   "source": [
    "### Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0026db23-163e-4454-a351-e30f3c253a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoting Reshape:\n",
      " Subject  Math  Science\n",
      "ID                    \n",
      "1        85.0     80.0\n",
      "3        90.0      NaN\n",
      "4         NaN     85.0\n"
     ]
    }
   ],
   "source": [
    "df8 = pd.DataFrame({\n",
    "    'ID': [1, 1, 3, 4],\n",
    "    'Subject': ['Math', 'Science', 'Math', 'Science'],\n",
    "    'Score': [85, 80, 90, 85]\n",
    "})\n",
    "pivoted = df8.pivot(index='ID', columns='Subject', values='Score')\n",
    "print(\"Pivoting Reshape:\\n\", pivoted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e8931-4a3b-4051-a137-ec79336e1c0c",
   "metadata": {},
   "source": [
    "### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c45fd9c-7a8a-40ed-abb3-0ab2055e1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Stacked DataFrame:\n",
      " ID         \n",
      "1   Math       85\n",
      "    Science    80\n",
      "2   Math       90\n",
      "    Science    85\n",
      "3   Math       78\n",
      "    Science    88\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df9 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Math': [85, 90, 78],\n",
    "    'Science': [80, 85, 88]\n",
    "})\n",
    "stacked = df9.set_index('ID').stack()\n",
    "print(\"Printing Stacked DataFrame:\\n\", stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d706b-7ab8-45de-bf59-1c47e1700fff",
   "metadata": {},
   "source": [
    "### Unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ddd89b7-19d1-4dee-b0ca-043e81385e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing Unstacked DataFrame:\n",
      "     Math  Science\n",
      "ID               \n",
      "1     85       80\n",
      "2     90       85\n",
      "3     78       88\n"
     ]
    }
   ],
   "source": [
    "unstacked = stacked.unstack()\n",
    "print(\"\\nPrinting Unstacked DataFrame:\\n\", unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99174201-90aa-4ecc-8c99-2e8a24d7d70c",
   "metadata": {},
   "source": [
    "## 5. Grouping and Aggregating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38f08e-b0dd-4205-9389-ee64f7d27beb",
   "metadata": {},
   "source": [
    "### Group By and Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fdab623-0634-4bed-972c-e654b12a9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Mean Scores: Course\n",
      "AOA    67.5\n",
      "CFP    52.5\n",
      "DSA    87.5\n",
      "NLP    80.0\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df10 = pd.DataFrame({\n",
    "    'ID': [1, 3, 1, 2, 2, 3, 1],\n",
    "    'Course': ['CFP', 'DSA', 'AOA', 'NLP', 'CFP', 'DSA', 'AOA'],\n",
    "    'Score': [50, 85, 65, 80, 55, 90, 70]\n",
    "})\n",
    "grouped_mean = df10.groupby('Course')['Score'].mean()\n",
    "print(\"Grouped Mean Scores:\", grouped_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247814ac-a5ef-4e08-8cf9-0b14db3266f8",
   "metadata": {},
   "source": [
    "### Multiple Aggregation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab7eaaeb-b72b-462d-8452-118436533b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple Aggregations:\n",
      "        Score           \n",
      "        mean  sum count\n",
      "Course                 \n",
      "AOA     67.5  135     2\n",
      "CFP     52.5  105     2\n",
      "DSA     87.5  175     2\n",
      "NLP     80.0   80     1\n"
     ]
    }
   ],
   "source": [
    "multiple_aggs = df10.groupby('Course').agg({'Score': ['mean', 'sum', 'count']})\n",
    "print(\"\\nMultiple Aggregations:\\n\", multiple_aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac10f6-3b9f-4fa2-9651-ad73e195cda1",
   "metadata": {},
   "source": [
    "### Group By and Apply Custom Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91c2376b-a8ae-4393-816c-2080d2340a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard Deviation of Scores USing Custom Function in Groupby:\n",
      " Course\n",
      "AOA    3.535534\n",
      "CFP    3.535534\n",
      "DSA    3.535534\n",
      "NLP         NaN\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "custom_func = df10.groupby('Course')['Score'].apply(lambda x: x.std())\n",
    "print(\"\\nStandard Deviation of Scores USing Custom Function in Groupby:\\n\", custom_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8cdd72-056f-4fbd-83c5-3894ca0893e8",
   "metadata": {},
   "source": [
    "# Mini Project: E-commerce Sales and Customer Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5a2ad-f224-4ee7-be5e-2b144d9dde40",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b81a82e-abcc-4cbd-9fc2-e7956b729829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset:\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "3         4          104           3        Shoes         1            50.0   \n",
      "4         5          105           2        Pants         2            25.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City  \n",
      "0         40.0        Fatima       Karachi  \n",
      "1         30.0         Imran        Lahore  \n",
      "2         60.0          Zain     Islamabad  \n",
      "3         50.0          Adil    Rawalpindi  \n",
      "4         50.0         Hamza    Faisalabad  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "'Order_ID': [1, 2, 3, 4, 5],\n",
    "'Customer_ID': [101, 102, 103, 104, 105],\n",
    "'Product_ID': [1, 2, 1, 3, 2],\n",
    "'Product_Name': ['Shirt', 'Pants', 'Shirt', 'Shoes', 'Pants'],\n",
    "'Quantity': [2, 1, 3, 1, 2],\n",
    "'Price_Per_Unit': [20.0, 30.0, 20.0, 50.0, 25.0],\n",
    "'Total_Price': [40.0, 30.0, 60.0, 50.0, 50.0],\n",
    "'Customer_Name': ['Fatima', 'Imran', 'Zain', 'Adil', 'Hamza'],\n",
    "'Customer_City': ['Karachi', 'Lahore', 'Islamabad', 'Rawalpindi', 'Faisalabad']\n",
    "}\n",
    "df_orders = pd.DataFrame(data)\n",
    "print(\"Initial dataset:\\n\", df_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea58c0e-0766-4110-b063-70f36eff8946",
   "metadata": {},
   "source": [
    "### Merging DataFrames on Single and Multiple Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ae8703b-dda5-4c7e-a0e7-b025f2d49754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame on single key (Customer_ID):\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "3         4          104           3        Shoes         1            50.0   \n",
      "4         5          105           2        Pants         2            25.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City      Customer_Email  Customer_Age  \n",
      "0         40.0        Fatima       Karachi  fatima@example.com          28.0  \n",
      "1         30.0         Imran        Lahore   imran@example.com          35.0  \n",
      "2         60.0          Zain     Islamabad  zainab@example.com          30.0  \n",
      "3         50.0          Adil    Rawalpindi                 NaN           NaN  \n",
      "4         50.0         Hamza    Faisalabad                 NaN           NaN  \n",
      "\n",
      "Merged DataFrame on multiple keys (Product_ID, Product_Name):\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "3         4          104           3        Shoes         1            50.0   \n",
      "4         5          105           2        Pants         2            25.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City Product_Category  \\\n",
      "0         40.0        Fatima       Karachi         Clothing   \n",
      "1         30.0         Imran        Lahore         Clothing   \n",
      "2         60.0          Zain     Islamabad         Clothing   \n",
      "3         50.0          Adil    Rawalpindi         Footwear   \n",
      "4         50.0         Hamza    Faisalabad         Clothing   \n",
      "\n",
      "  Product_Subcategory  \n",
      "0               Shirt  \n",
      "1               Pants  \n",
      "2               Shirt  \n",
      "3               Shoes  \n",
      "4               Pants  \n"
     ]
    }
   ],
   "source": [
    "df_customer_info = pd.DataFrame({\n",
    "'Customer_ID': [101, 102, 103],\n",
    "'Customer_Email': ['fatima@example.com', 'imran@example.com', 'zainab@example.com'],\n",
    "'Customer_Age': [28, 35, 30]\n",
    "})\n",
    "\n",
    "# Merge on single key (Customer_ID)\n",
    "merged_single_key = pd.merge(df_orders, df_customer_info, on='Customer_ID', how='left')\n",
    "print(\"\\nMerged DataFrame on single key (Customer_ID):\\n\", merged_single_key)\n",
    "\n",
    "df_product_info = pd.DataFrame({\n",
    "'Product_ID': [1, 2, 3],\n",
    "'Product_Name': ['Shirt', 'Pants', 'Shoes'],\n",
    "'Product_Category': ['Clothing', 'Clothing', 'Footwear'],\n",
    "'Product_Subcategory': ['Shirt', 'Pants', 'Shoes']\n",
    "})\n",
    "\n",
    "# Merge on multiple keys (Product_ID, Product_Name)\n",
    "merged_multiple_keys = pd.merge(df_orders, df_product_info, on=['Product_ID', 'Product_Name'], how='left')\n",
    "print(\"\\nMerged DataFrame on multiple keys (Product_ID, Product_Name):\\n\", merged_multiple_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ccbe69-f029-49f2-9ba2-2f9351690292",
   "metadata": {},
   "source": [
    "### Performing Different Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7534ba42-7941-4c47-8f21-b4cfbe6315bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inner Join:\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City      Customer_Email  Customer_Age  \n",
      "0         40.0        Fatima       Karachi  fatima@example.com            28  \n",
      "1         30.0         Imran        Lahore   imran@example.com            35  \n",
      "2         60.0          Zain     Islamabad  zainab@example.com            30  \n",
      "\n",
      "Outer Join:\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "3         4          104           3        Shoes         1            50.0   \n",
      "4         5          105           2        Pants         2            25.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City      Customer_Email  Customer_Age  \n",
      "0         40.0        Fatima       Karachi  fatima@example.com          28.0  \n",
      "1         30.0         Imran        Lahore   imran@example.com          35.0  \n",
      "2         60.0          Zain     Islamabad  zainab@example.com          30.0  \n",
      "3         50.0          Adil    Rawalpindi                 NaN           NaN  \n",
      "4         50.0         Hamza    Faisalabad                 NaN           NaN  \n",
      "\n",
      "Left Join:\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "3         4          104           3        Shoes         1            50.0   \n",
      "4         5          105           2        Pants         2            25.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City      Customer_Email  Customer_Age  \n",
      "0         40.0        Fatima       Karachi  fatima@example.com          28.0  \n",
      "1         30.0         Imran        Lahore   imran@example.com          35.0  \n",
      "2         60.0          Zain     Islamabad  zainab@example.com          30.0  \n",
      "3         50.0          Adil    Rawalpindi                 NaN           NaN  \n",
      "4         50.0         Hamza    Faisalabad                 NaN           NaN  \n",
      "\n",
      "Right Join:\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City      Customer_Email  Customer_Age  \n",
      "0         40.0        Fatima       Karachi  fatima@example.com            28  \n",
      "1         30.0         Imran        Lahore   imran@example.com            35  \n",
      "2         60.0          Zain     Islamabad  zainab@example.com            30  \n"
     ]
    }
   ],
   "source": [
    "# Inner Join\n",
    "inner_joined = pd.merge(df_orders, df_customer_info, on='Customer_ID', how='inner')\n",
    "print(\"\\nInner Join:\\n\", inner_joined)\n",
    "\n",
    "# Outer Join\n",
    "outer_joined = pd.merge(df_orders, df_customer_info, on='Customer_ID', how='outer')\n",
    "print(\"\\nOuter Join:\\n\", outer_joined)\n",
    "\n",
    "# Left Join\n",
    "left_joined = pd.merge(df_orders, df_customer_info, on='Customer_ID', how='left')\n",
    "print(\"\\nLeft Join:\\n\", left_joined)\n",
    "\n",
    "# Right Join\n",
    "right_joined = pd.merge(df_orders, df_customer_info, on='Customer_ID', how='right')\n",
    "print(\"\\nRight Join:\\n\", right_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6fe5f3-f698-420e-8631-511cac40242e",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "769b8a10-1b7d-4fbc-9804-ceffe1c67713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenate along Rows:\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "3         4          104           3        Shoes         1            50.0   \n",
      "4         5          105           2        Pants         2            25.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City  \n",
      "0         40.0        Fatima       Karachi  \n",
      "1         30.0         Imran        Lahore  \n",
      "2         60.0          Zain     Islamabad  \n",
      "3         50.0          Adil    Rawalpindi  \n",
      "4         50.0         Hamza    Faisalabad  \n",
      "\n",
      "Concatenate along Columns:\n",
      "    Order_ID  Customer_ID  Product_ID  Total_Price\n",
      "0         1          101           1         40.0\n",
      "1         2          102           2         30.0\n",
      "2         3          103           1         60.0\n",
      "3         4          104           3         50.0\n",
      "4         5          105           2         50.0\n",
      "\n",
      "Concatenate List of DataFrames:\n",
      "    Order_ID  Customer_ID  Product_ID Product_Name  Quantity  Price_Per_Unit  \\\n",
      "0         1          101           1        Shirt         2            20.0   \n",
      "1         2          102           2        Pants         1            30.0   \n",
      "2         3          103           1        Shirt         3            20.0   \n",
      "3         4          104           3        Shoes         1            50.0   \n",
      "4         5          105           2        Pants         2            25.0   \n",
      "\n",
      "   Total_Price Customer_Name Customer_City  \n",
      "0         40.0        Fatima       Karachi  \n",
      "1         30.0         Imran        Lahore  \n",
      "2         60.0          Zain     Islamabad  \n",
      "3         50.0          Adil    Rawalpindi  \n",
      "4         50.0         Hamza    Faisalabad  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate along rows\n",
    "concat_rows = pd.concat([df_orders.head(2), df_orders.tail(3)], axis=0)\n",
    "print(\"\\nConcatenate along Rows:\\n\", concat_rows)\n",
    "\n",
    "# Concatenate along columns\n",
    "concat_cols = pd.concat([df_orders[['Order_ID', 'Customer_ID']], df_orders[['Product_ID', 'Total_Price']]], axis=1)\n",
    "print(\"\\nConcatenate along Columns:\\n\", concat_cols)\n",
    "\n",
    "# Concatenate a list of DataFrames\n",
    "dfs_list = [df_orders.head(2), df_orders.tail(3)]\n",
    "concat_list = pd.concat(dfs_list, axis=0)\n",
    "print(\"\\nConcatenate List of DataFrames:\\n\", concat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63dc0f-663c-494e-8625-ad14d0860c26",
   "metadata": {},
   "source": [
    "### Reshaping Data using Melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "266ab46b-ffe0-4bbb-902b-2eb3304529ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melted DataFrame:\n",
      "    Order_ID  Customer_ID      Variable  Value\n",
      "0         1          101  Product_Name  Shirt\n",
      "1         2          102  Product_Name  Pants\n",
      "2         3          103  Product_Name  Shirt\n",
      "3         4          104  Product_Name  Shoes\n",
      "4         5          105  Product_Name  Pants\n",
      "5         1          101      Quantity      2\n",
      "6         2          102      Quantity      1\n",
      "7         3          103      Quantity      3\n",
      "8         4          104      Quantity      1\n",
      "9         5          105      Quantity      2\n"
     ]
    }
   ],
   "source": [
    "# Melt the DataFrame\n",
    "melted = pd.melt(df_orders, id_vars=['Order_ID', 'Customer_ID'], value_vars=['Product_Name', 'Quantity'], var_name='Variable', value_name='Value')\n",
    "print(\"\\nMelted DataFrame:\\n\", melted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ea0c2-f9d3-4aed-b44d-a46d096f8d96",
   "metadata": {},
   "source": [
    "### Creating Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b899e1-8d3b-4967-8715-1ab8167d9aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot Table:\n",
      " Product_Name   Pants  Shirt  Shoes\n",
      "Customer_City                     \n",
      "Faisalabad      50.0    NaN    NaN\n",
      "Islamabad        NaN   60.0    NaN\n",
      "Karachi          NaN   40.0    NaN\n",
      "Lahore          30.0    NaN    NaN\n",
      "Rawalpindi       NaN    NaN   50.0\n"
     ]
    }
   ],
   "source": [
    "# Create Pivot Table\n",
    "pivot_table = df_orders.pivot_table(index='Customer_City', columns='Product_Name', values='Total_Price', aggfunc='sum')\n",
    "print(\"\\nPivot Table:\\n\", pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b2a9a-76c8-433f-97f7-f5b7a2ae2151",
   "metadata": {},
   "source": [
    "### Grouping Data and Performing Aggregation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af272938-a8b3-44dd-9e45-fab666a17316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Sales by Customer City:\n",
      " Customer_City\n",
      "Faisalabad    50.0\n",
      "Islamabad     60.0\n",
      "Karachi       40.0\n",
      "Lahore        30.0\n",
      "Rawalpindi    50.0\n",
      "Name: Total_Price, dtype: float64\n",
      "\n",
      "Multiple Aggregations on Total Price by Customer City:\n",
      "               Total_Price            \n",
      "                      sum  mean count\n",
      "Customer_City                        \n",
      "Faisalabad           50.0  50.0     1\n",
      "Islamabad            60.0  60.0     1\n",
      "Karachi              40.0  40.0     1\n",
      "Lahore               30.0  30.0     1\n",
      "Rawalpindi           50.0  50.0     1\n"
     ]
    }
   ],
   "source": [
    "# Group by Customer_City and calculate total sales\n",
    "grouped_sales = df_orders.groupby('Customer_City')['Total_Price'].sum()\n",
    "print(\"\\nTotal Sales by Customer City:\\n\", grouped_sales)\n",
    "\n",
    "# Multiple aggregations\n",
    "multiple_aggs = df_orders.groupby('Customer_City').agg({'Total_Price': ['sum', 'mean', 'count']})\n",
    "print(\"\\nMultiple Aggregations on Total Price by Customer City:\\n\", multiple_aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ce0c9-f664-4a81-9619-c161afed3df3",
   "metadata": {},
   "source": [
    "### Applying Custom Functions to Grouped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c4959fb-49a9-4d22-9d0c-197befefadad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Price per Unit by Customer City:\n",
      " Customer_City\n",
      "Faisalabad    25.0\n",
      "Islamabad     20.0\n",
      "Karachi       20.0\n",
      "Lahore        30.0\n",
      "Rawalpindi    50.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def avg_price_per_unit(x):\n",
    "    total_quantity = x['Quantity'].sum()\n",
    "    total_price = x['Total_Price'].sum()\n",
    "    return total_price / total_quantity if total_quantity != 0 else 0\n",
    "\n",
    "avg_price_per_unit_by_city = df_orders.groupby('Customer_City').apply(avg_price_per_unit)\n",
    "print(\"\\nAverage Price per Unit by Customer City:\\n\", avg_price_per_unit_by_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5644af-7e44-4a9d-b01e-e097b8bc7663",
   "metadata": {},
   "source": [
    "# Practice on a DataSet from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd919e-f0b9-4bc7-b034-62f1f4dfa016",
   "metadata": {},
   "source": [
    "### Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4511069e-3618-44ac-8e82-af454decf668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year                   Player   Age       School  Height      Weight  \\\n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "\n",
      "   Sprint_40yd  Vertical_Jump  Bench_Press_Reps  Broad_Jump  Agility_3cone  \\\n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "\n",
      "   Shuttle                          Drafted..tm.rnd.yr.        BMI  \\\n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "\n",
      "  Player_Type      Position_Type Position Drafted  \n",
      "0     offense    backs_receivers       RB     Yes  \n",
      "1     defense  defensive_lineman       DE     Yes  \n",
      "2     offense  offensive_lineman       OG     Yes  \n",
      "3     defense     defensive_back       FS     Yes  \n",
      "4     defense        line_backer      OLB     Yes  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('NFL.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083bb13-50dd-425e-8a0c-41db5a92efc2",
   "metadata": {},
   "source": [
    "### Merge on single key (Player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aafd712e-347b-45fb-80e7-9628636e1dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame on single key (Player):\n",
      "    Year                   Player   Age       School  Height      Weight  \\\n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "\n",
      "   Sprint_40yd  Vertical_Jump  Bench_Press_Reps  Broad_Jump  Agility_3cone  \\\n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "\n",
      "   Shuttle                          Drafted..tm.rnd.yr.        BMI  \\\n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "\n",
      "  Player_Type      Position_Type Position Drafted  Additional_Stat  \n",
      "0     offense    backs_receivers       RB     Yes              NaN  \n",
      "1     defense  defensive_lineman       DE     Yes              NaN  \n",
      "2     offense  offensive_lineman       OG     Yes              NaN  \n",
      "3     defense     defensive_back       FS     Yes              NaN  \n",
      "4     defense        line_backer      OLB     Yes              NaN  \n"
     ]
    }
   ],
   "source": [
    "df_additional = pd.DataFrame({\n",
    "    'Player': ['Player A', 'Player B', 'Player C'],\n",
    "    'Additional_Stat': [100, 150, 200]\n",
    "})\n",
    "merged_single_key = pd.merge(df, df_additional, on='Player', how='left')\n",
    "print(\"\\nMerged DataFrame on single key (Player):\\n\", merged_single_key.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f95aae0-bf47-40a7-99f4-0b54fc0019be",
   "metadata": {},
   "source": [
    "### Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e36a27-c884-44e9-b816-a54d0ce88466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inner Join:\n",
      " Empty DataFrame\n",
      "Columns: [Year, Player, Age, School, Height, Weight, Sprint_40yd, Vertical_Jump, Bench_Press_Reps, Broad_Jump, Agility_3cone, Shuttle, Drafted..tm.rnd.yr., BMI, Player_Type, Position_Type, Position, Drafted, Additional_Stat]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "inner_joined = pd.merge(df, df_additional, on='Player', how='inner')\n",
    "print(\"\\nInner Join:\\n\", inner_joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e69d7-0a37-4dd6-a217-8a65a887a13e",
   "metadata": {},
   "source": [
    "### Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ef8ef3a-1612-487d-bd61-36c77ab3839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Join:\n",
      "      Year                   Player   Age       School  Height      Weight  \\\n",
      "0  2009.0    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009.0      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009.0  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009.0  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009.0      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "\n",
      "   Sprint_40yd  Vertical_Jump  Bench_Press_Reps  Broad_Jump  Agility_3cone  \\\n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "\n",
      "   Shuttle                          Drafted..tm.rnd.yr.        BMI  \\\n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "\n",
      "  Player_Type      Position_Type Position Drafted  Additional_Stat  \n",
      "0     offense    backs_receivers       RB     Yes              NaN  \n",
      "1     defense  defensive_lineman       DE     Yes              NaN  \n",
      "2     offense  offensive_lineman       OG     Yes              NaN  \n",
      "3     defense     defensive_back       FS     Yes              NaN  \n",
      "4     defense        line_backer      OLB     Yes              NaN  \n"
     ]
    }
   ],
   "source": [
    "outer_joined = pd.merge(df, df_additional, on='Player', how='outer')\n",
    "print(\"\\nOuter Join:\\n\", outer_joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23307587-468a-4b63-a367-ce7dbede318d",
   "metadata": {},
   "source": [
    "### Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dec4420-d170-4e8a-a8e1-53ba648b1154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Left Join:\n",
      "    Year                   Player   Age       School  Height      Weight  \\\n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "\n",
      "   Sprint_40yd  Vertical_Jump  Bench_Press_Reps  Broad_Jump  Agility_3cone  \\\n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "\n",
      "   Shuttle                          Drafted..tm.rnd.yr.        BMI  \\\n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "\n",
      "  Player_Type      Position_Type Position Drafted  Additional_Stat  \n",
      "0     offense    backs_receivers       RB     Yes              NaN  \n",
      "1     defense  defensive_lineman       DE     Yes              NaN  \n",
      "2     offense  offensive_lineman       OG     Yes              NaN  \n",
      "3     defense     defensive_back       FS     Yes              NaN  \n",
      "4     defense        line_backer      OLB     Yes              NaN  \n"
     ]
    }
   ],
   "source": [
    "left_joined = pd.merge(df, df_additional, on='Player', how='left')\n",
    "print(\"\\nLeft Join:\\n\", left_joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26efea-e1bd-463c-88b6-2aa84bb4d3b0",
   "metadata": {},
   "source": [
    "### Right Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdd06d5a-03c9-46d7-96e3-e10b0dd9f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Right Join:\n",
      "    Year    Player  Age School  Height  Weight  Sprint_40yd  Vertical_Jump  \\\n",
      "0   NaN  Player A  NaN    NaN     NaN     NaN          NaN            NaN   \n",
      "1   NaN  Player B  NaN    NaN     NaN     NaN          NaN            NaN   \n",
      "2   NaN  Player C  NaN    NaN     NaN     NaN          NaN            NaN   \n",
      "\n",
      "   Bench_Press_Reps  Broad_Jump  Agility_3cone  Shuttle Drafted..tm.rnd.yr.  \\\n",
      "0               NaN         NaN            NaN      NaN                 NaN   \n",
      "1               NaN         NaN            NaN      NaN                 NaN   \n",
      "2               NaN         NaN            NaN      NaN                 NaN   \n",
      "\n",
      "   BMI Player_Type Position_Type Position Drafted  Additional_Stat  \n",
      "0  NaN         NaN           NaN      NaN     NaN              100  \n",
      "1  NaN         NaN           NaN      NaN     NaN              150  \n",
      "2  NaN         NaN           NaN      NaN     NaN              200  \n"
     ]
    }
   ],
   "source": [
    "right_joined = pd.merge(df, df_additional, on='Player', how='right')\n",
    "print(\"\\nRight Join:\\n\", right_joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59e569-f487-4e42-b44c-18e4354c116f",
   "metadata": {},
   "source": [
    "### Concatenate along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "008b8269-008f-42f3-96c9-dc8955e27615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenate along Rows:\n",
      "    Year                   Player   Age       School  Height      Weight  \\\n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "\n",
      "   Sprint_40yd  Vertical_Jump  Bench_Press_Reps  Broad_Jump  Agility_3cone  \\\n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "\n",
      "   Shuttle                          Drafted..tm.rnd.yr.        BMI  \\\n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "\n",
      "  Player_Type      Position_Type Position Drafted  \n",
      "0     offense    backs_receivers       RB     Yes  \n",
      "1     defense  defensive_lineman       DE     Yes  \n",
      "2     offense  offensive_lineman       OG     Yes  \n",
      "3     defense     defensive_back       FS     Yes  \n",
      "4     defense        line_backer      OLB     Yes  \n",
      "0     offense    backs_receivers       RB     Yes  \n",
      "1     defense  defensive_lineman       DE     Yes  \n",
      "2     offense  offensive_lineman       OG     Yes  \n",
      "3     defense     defensive_back       FS     Yes  \n",
      "4     defense        line_backer      OLB     Yes  \n"
     ]
    }
   ],
   "source": [
    "concat_rows = pd.concat([df.head(), df.head()], axis=0)\n",
    "print(\"\\nConcatenate along Rows:\\n\", concat_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5fceb1-86f2-46c5-992f-40e0ef778eb1",
   "metadata": {},
   "source": [
    "### Concatenate along columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ea900be-17a7-4142-8cc3-114bebf958ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenate along Columns:\n",
      "    Year                   Player   Age       School  Height      Weight  \\\n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "\n",
      "   Sprint_40yd  Vertical_Jump  Bench_Press_Reps  Broad_Jump  Agility_3cone  \\\n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "\n",
      "   Shuttle                          Drafted..tm.rnd.yr.        BMI  \\\n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "\n",
      "  Player_Type      Position_Type Position Drafted    Player  Additional_Stat  \n",
      "0     offense    backs_receivers       RB     Yes  Player A            100.0  \n",
      "1     defense  defensive_lineman       DE     Yes  Player B            150.0  \n",
      "2     offense  offensive_lineman       OG     Yes  Player C            200.0  \n",
      "3     defense     defensive_back       FS     Yes       NaN              NaN  \n",
      "4     defense        line_backer      OLB     Yes       NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "concat_cols = pd.concat([df.head(), df_additional], axis=1)\n",
    "print(\"\\nConcatenate along Columns:\\n\", concat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec834bc-bdd3-4252-9221-830b3b2a7a8b",
   "metadata": {},
   "source": [
    "### Concatenate list of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "188d4b3d-3b17-4294-b659-46ba715eeb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenate List of DataFrames:\n",
      "    Year                   Player   Age       School  Height      Weight  \\\n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "0  2009    Beanie Wells\\WellCh00  20.0     Ohio St.  1.8542  106.594207   \n",
      "1  2009      Will Davis\\DaviWi99  22.0     Illinois  1.8796  118.387609   \n",
      "2  2009  Herman Johnson\\JohnHe23  24.0          LSU  2.0066  165.107623   \n",
      "3  2009  Rashad Johnson\\JohnRa98  23.0      Alabama  1.8034   92.079251   \n",
      "4  2009      Cody Brown\\BrowCo96  22.0  Connecticut  1.8796  110.676538   \n",
      "\n",
      "   Sprint_40yd  Vertical_Jump  Bench_Press_Reps  Broad_Jump  Agility_3cone  \\\n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "0         4.38          85.09              25.0      325.12            NaN   \n",
      "1         4.84          83.82              27.0      292.10           7.38   \n",
      "2         5.50            NaN              21.0         NaN            NaN   \n",
      "3         4.49          93.98              15.0      304.80           7.09   \n",
      "4         4.76          92.71              26.0      304.80           7.10   \n",
      "\n",
      "   Shuttle                          Drafted..tm.rnd.yr.        BMI  \\\n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "0      NaN   Arizona Cardinals / 1st / 31st pick / 2009  31.004194   \n",
      "1     4.45  Arizona Cardinals / 6th / 204th pick / 2009  33.510073   \n",
      "2      NaN  Arizona Cardinals / 5th / 167th pick / 2009  41.005821   \n",
      "3     4.23   Arizona Cardinals / 3rd / 95th pick / 2009  28.312463   \n",
      "4     4.40   Arizona Cardinals / 2nd / 63rd pick / 2009  31.327425   \n",
      "\n",
      "  Player_Type      Position_Type Position Drafted  \n",
      "0     offense    backs_receivers       RB     Yes  \n",
      "1     defense  defensive_lineman       DE     Yes  \n",
      "2     offense  offensive_lineman       OG     Yes  \n",
      "3     defense     defensive_back       FS     Yes  \n",
      "4     defense        line_backer      OLB     Yes  \n",
      "0     offense    backs_receivers       RB     Yes  \n",
      "1     defense  defensive_lineman       DE     Yes  \n",
      "2     offense  offensive_lineman       OG     Yes  \n",
      "3     defense     defensive_back       FS     Yes  \n",
      "4     defense        line_backer      OLB     Yes  \n",
      "0     offense    backs_receivers       RB     Yes  \n",
      "1     defense  defensive_lineman       DE     Yes  \n",
      "2     offense  offensive_lineman       OG     Yes  \n",
      "3     defense     defensive_back       FS     Yes  \n",
      "4     defense        line_backer      OLB     Yes  \n"
     ]
    }
   ],
   "source": [
    "dfs_list = [df.head(), df.head(), df.head()]\n",
    "concat_list = pd.concat(dfs_list, axis=0)\n",
    "print(\"\\nConcatenate List of DataFrames:\\n\", concat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df8cd9-3b76-4c3d-9e38-1e6230b6280d",
   "metadata": {},
   "source": [
    "### Melt the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "942db623-fcf5-4706-9591-32fa2cb7b591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melted DataFrame:\n",
      "                     Player  Year          Event  Score\n",
      "0    Beanie Wells\\WellCh00  2009    Sprint_40yd   4.38\n",
      "1      Will Davis\\DaviWi99  2009    Sprint_40yd   4.84\n",
      "2  Herman Johnson\\JohnHe23  2009    Sprint_40yd   5.50\n",
      "3  Rashad Johnson\\JohnRa98  2009    Sprint_40yd   4.49\n",
      "4      Cody Brown\\BrowCo96  2009    Sprint_40yd   4.76\n",
      "5    Beanie Wells\\WellCh00  2009  Vertical_Jump  85.09\n",
      "6      Will Davis\\DaviWi99  2009  Vertical_Jump  83.82\n",
      "7  Herman Johnson\\JohnHe23  2009  Vertical_Jump    NaN\n",
      "8  Rashad Johnson\\JohnRa98  2009  Vertical_Jump  93.98\n",
      "9      Cody Brown\\BrowCo96  2009  Vertical_Jump  92.71\n"
     ]
    }
   ],
   "source": [
    "melted = pd.melt(df.head(), id_vars=['Player', 'Year'], value_vars=['Sprint_40yd', 'Vertical_Jump'], var_name='Event', value_name='Score')\n",
    "print(\"\\nMelted DataFrame:\\n\", melted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d05b1c-7e8a-49b4-a08a-4fcd279d6d1c",
   "metadata": {},
   "source": [
    "### Create Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0a1894e-4ea5-41d1-af81-6fa49cf48f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot Table:\n",
      " Position         C        CB    DB        DE        DT        FB        FS  \\\n",
      "Year                                                                         \n",
      "2009      5.225833  4.488529   NaN  4.798000  5.031250  4.691000  4.496154   \n",
      "2010      5.228750  4.493636   NaN  4.846087  5.083846  4.770000  4.526154   \n",
      "2011      5.193333  4.482857   NaN  4.819615  5.088750  4.824286  4.567000   \n",
      "2012      5.248571  4.504444   NaN  4.792917  5.049655  4.647500  4.535714   \n",
      "2013      5.328889  4.490000   NaN  4.812083  5.143600  4.832000  4.618333   \n",
      "2014      5.224167  4.513333   NaN  4.848696  5.106538  4.807500  4.565000   \n",
      "2015      5.191250  4.506061   NaN  4.814167  5.123077  4.780000  4.600714   \n",
      "2016      5.208889  4.498378   NaN  4.879375  5.070000  4.724000  4.591000   \n",
      "2017      5.352000  4.491290   NaN  4.792800  5.110556  4.840000  4.528571   \n",
      "2018      5.286667  4.499722  4.46  4.837692  5.154000       NaN       NaN   \n",
      "2019           NaN  4.504688   NaN       NaN       NaN  4.890000       NaN   \n",
      "\n",
      "Position       ILB         K     LS        OG       OLB        OT         P  \\\n",
      "Year                                                                          \n",
      "2009      4.695714  4.825000  4.990  5.310909  4.656190  5.189600  4.858333   \n",
      "2010      4.803529  4.940000  5.080  5.290000  4.697273  5.204000  4.820000   \n",
      "2011      4.722000  4.938000  5.000  5.341364  4.679565  5.262917  4.805000   \n",
      "2012      4.678333  5.035000  4.820  5.260000  4.667200  5.243333  4.906667   \n",
      "2013      4.778571  4.790000  5.050  5.251000  4.705769  5.194828  4.917778   \n",
      "2014      4.812727  4.860000  4.910  5.243810  4.700000  5.213529  4.972000   \n",
      "2015      4.755000  5.068000  4.910  5.389000  4.728400  5.216400  5.075714   \n",
      "2016      4.787647  4.851667  4.950  5.286000  4.688182  5.238824  4.996667   \n",
      "2017      4.741818  4.790000  5.245  5.250952  4.680588  5.323571  4.810000   \n",
      "2018      4.716667  4.940000  5.000  5.291667  4.620769  5.255000  4.905000   \n",
      "2019           NaN       NaN  5.000       NaN       NaN  5.193600  4.693333   \n",
      "\n",
      "Position        QB        RB         S        SS        TE        WR  \n",
      "Year                                                                  \n",
      "2009      4.862381  4.515769       NaN  4.520000  4.726000  4.455682  \n",
      "2010      4.823889  4.537200       NaN  4.575000  4.705556  4.513478  \n",
      "2011      4.801111  4.535000       NaN  4.585455  4.722000  4.496087  \n",
      "2012      4.746316  4.502222       NaN  4.558125  4.700833  4.477872  \n",
      "2013      4.850625  4.590000       NaN  4.550000  4.766842  4.505263  \n",
      "2014      4.858235  4.577187       NaN  4.570909  4.773810  4.509796  \n",
      "2015      4.817143  4.603333       NaN  4.578750  4.811111  4.502500  \n",
      "2016      4.837222  4.530833       NaN  4.581667  4.757857  4.546047  \n",
      "2017      4.790833  4.553333       NaN  4.523636  4.665333  4.520612  \n",
      "2018      4.855294  4.589231  4.525000       NaN  4.740769  4.518108  \n",
      "2019      4.776000  4.561818  4.542727       NaN  4.751579  4.495946  \n"
     ]
    }
   ],
   "source": [
    "pivot_table = df.pivot_table(index='Year', columns='Position', values='Sprint_40yd', aggfunc='mean')\n",
    "print(\"\\nPivot Table:\\n\", pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e65575-0be9-4399-b84e-3d6e9b4d860b",
   "metadata": {},
   "source": [
    "### Group by Position and calculate mean Sprint_40yd and Multiple aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65e67b1d-0a76-4efd-8cc8-d3ed27507a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped Mean Sprint_40yd by Position:\n",
      " Position\n",
      "C      5.241882\n",
      "CB     4.497723\n",
      "DB     4.460000\n",
      "DE     4.824895\n",
      "DT     5.093862\n",
      "FB     4.762500\n",
      "FS     4.560319\n",
      "ILB    4.751314\n",
      "K      4.910000\n",
      "LS     5.014615\n",
      "OG     5.292043\n",
      "OLB    4.686696\n",
      "OT     5.226628\n",
      "P      4.911667\n",
      "QB     4.821189\n",
      "RB     4.555523\n",
      "S      4.534286\n",
      "SS     4.561456\n",
      "TE     4.741620\n",
      "WR     4.503646\n",
      "Name: Sprint_40yd, dtype: float64\n",
      "\n",
      "Multiple Aggregations on Sprint_40yd by Position:\n",
      "          Sprint_40yd               \n",
      "                mean      sum count\n",
      "Position                           \n",
      "C           5.241882   445.56    85\n",
      "CB          4.497723  1718.13   382\n",
      "DB          4.460000     4.46     1\n",
      "DE          4.824895  1153.15   239\n",
      "DT          5.093862  1253.09   246\n",
      "FB          4.762500   228.60    48\n",
      "FS          4.560319   428.67    94\n",
      "ILB         4.751314   650.93   137\n",
      "K           4.910000   171.85    35\n",
      "LS          5.014615    65.19    13\n",
      "OG          5.292043   984.32   186\n",
      "OLB         4.686696  1077.94   230\n",
      "OT          5.226628  1348.47   258\n",
      "P           4.911667   265.23    54\n",
      "QB          4.821189   891.92   185\n",
      "RB          4.555523  1393.99   306\n",
      "S           4.534286   190.44    42\n",
      "SS          4.561456   469.83   103\n",
      "TE          4.741620   848.75   179\n",
      "WR          4.503646  2161.75   480\n"
     ]
    }
   ],
   "source": [
    "grouped_mean = df.groupby('Position')['Sprint_40yd'].mean()\n",
    "print(\"\\nGrouped Mean Sprint_40yd by Position:\\n\", grouped_mean)\n",
    "multiple_aggs = df.groupby('Position').agg({'Sprint_40yd': ['mean', 'sum', 'count']})\n",
    "print(\"\\nMultiple Aggregations on Sprint_40yd by Position:\\n\", multiple_aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f862f-9e49-4dca-9f5a-0fbcc1b77c6f",
   "metadata": {},
   "source": [
    "### Custom function: standard deviation of Sprint_40yd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "195bd3d1-7ac3-4ee1-86a5-88c775af816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard Deviation of Sprint_40yd by Position:\n",
      " Position\n",
      "C      0.145606\n",
      "CB     0.090564\n",
      "DB          NaN\n",
      "DE     0.134810\n",
      "DT     0.173003\n",
      "FB     0.133073\n",
      "FS     0.096134\n",
      "ILB    0.125022\n",
      "K      0.146348\n",
      "LS     0.129010\n",
      "OG     0.184444\n",
      "OLB    0.116722\n",
      "OT     0.177057\n",
      "P      0.140950\n",
      "QB     0.167230\n",
      "RB     0.110738\n",
      "S      0.126455\n",
      "SS     0.084057\n",
      "TE     0.135369\n",
      "WR     0.097032\n",
      "Name: Sprint_40yd, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "custom_func = df.groupby('Position')['Sprint_40yd'].apply(lambda x: x.std())\n",
    "print(\"\\nStandard Deviation of Sprint_40yd by Position:\\n\", custom_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
